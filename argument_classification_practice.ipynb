{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the super important and useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the four datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dp = pd.read_csv('data/dp-slider-means.csv')\n",
    "raw_data_evo = pd.read_csv('data/evo-slider-means.csv')\n",
    "raw_data_gc = pd.read_csv('data/gc-slider-means.csv')\n",
    "raw_data_gm = pd.read_csv('data/gm-slider-means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the amount of rows and columns for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 8 columns\n",
      "Amount of rows:\n",
      " total: 5375 \n",
      " dp: 987 \n",
      " evo: 1252\n",
      " gc: 1590\n",
      " gm: 1546\n"
     ]
    }
   ],
   "source": [
    "n_rows = len(raw_data_dp) + len(raw_data_evo) + len(raw_data_gc) + len(raw_data_gm)\n",
    "\n",
    "print(\"The data contains {0} columns\".format(len(raw_data_dp.columns)))\n",
    "print(\"Amount of rows:\\n total: {0} \\n dp: {1} \\n evo: {2}\\n gc: {3}\\n gm: {4}\".format(n_rows, len(raw_data_dp),\n",
    "                                                                                       len(raw_data_evo), \n",
    "                                                                         len(raw_data_gc), len(raw_data_gm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all four datasets into one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [raw_data_dp, raw_data_evo, raw_data_gc, raw_data_gm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.concat(frames, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined dataset now contains 5375 rows and 8 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The combined dataset now contains {0} rows and {1} columns\".format(len(raw_data), len(raw_data.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the first 5 rows of the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>GoodSliderMean</th>\n",
       "      <th>GoodSliderDev</th>\n",
       "      <th>Connective.x</th>\n",
       "      <th>PairType.x</th>\n",
       "      <th>ResponseInitial.x</th>\n",
       "      <th>Phrase.x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>658</td>\n",
       "      <td>ab5810d83f23243ddce713ac23d775cd</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>so</td>\n",
       "      <td>P1_P2</td>\n",
       "      <td>false</td>\n",
       "      <td>Sorry for the length of the post, but I hope i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>871</td>\n",
       "      <td>e0a35a65ce12b2457e8ff1f9b8cec749</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no_connective</td>\n",
       "      <td>P1_P2</td>\n",
       "      <td>true</td>\n",
       "      <td>I am all for the death penalty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>931</td>\n",
       "      <td>f16863ac9454707946061848c7e9a3e5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no_connective</td>\n",
       "      <td>P1_P2</td>\n",
       "      <td>true</td>\n",
       "      <td>I am pro death penalty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>936</td>\n",
       "      <td>f1f99c6b1f3f14025a3c01cb8a13b10b</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_connective</td>\n",
       "      <td>P1_P2</td>\n",
       "      <td>false</td>\n",
       "      <td>I can't believe that you just said \"So what if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>029bc4e01ac943f87837556b32d5627a</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>so</td>\n",
       "      <td>QR</td>\n",
       "      <td>false</td>\n",
       "      <td>So what does he have to do with a debate like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            ItemId  GoodSliderMean  \\\n",
       "0         658  ab5810d83f23243ddce713ac23d775cd           1.000   \n",
       "1         871  e0a35a65ce12b2457e8ff1f9b8cec749           1.000   \n",
       "2         931  f16863ac9454707946061848c7e9a3e5           1.000   \n",
       "3         936  f1f99c6b1f3f14025a3c01cb8a13b10b           1.000   \n",
       "4          11  029bc4e01ac943f87837556b32d5627a           0.999   \n",
       "\n",
       "   GoodSliderDev   Connective.x PairType.x ResponseInitial.x  \\\n",
       "0            NaN             so      P1_P2             false   \n",
       "1       0.000000  no_connective      P1_P2              true   \n",
       "2       0.000000  no_connective      P1_P2              true   \n",
       "3            NaN  no_connective      P1_P2             false   \n",
       "4       0.001414             so         QR             false   \n",
       "\n",
       "                                            Phrase.x  \n",
       "0  Sorry for the length of the post, but I hope i...  \n",
       "1                    I am all for the death penalty.  \n",
       "2                            I am pro death penalty.  \n",
       "3  I can't believe that you just said \"So what if...  \n",
       "4  So what does he have to do with a debate like ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested in the argument score and the argument itself, so only keep that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[[\"GoodSliderMean\", \"Phrase.x\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we only have the arguments and its annotated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GoodSliderMean</th>\n",
       "      <th>Phrase.x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>Sorry for the length of the post, but I hope i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>I am all for the death penalty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>I am pro death penalty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>I can't believe that you just said \"So what if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999</td>\n",
       "      <td>So what does he have to do with a debate like ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GoodSliderMean                                           Phrase.x\n",
       "0           1.000  Sorry for the length of the post, but I hope i...\n",
       "1           1.000                    I am all for the death penalty.\n",
       "2           1.000                            I am pro death penalty.\n",
       "3           1.000  I can't believe that you just said \"So what if...\n",
       "4           0.999  So what does he have to do with a debate like ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ordered by topic and by argument score, so shuffle it before using it for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now properly shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GoodSliderMean</th>\n",
       "      <th>Phrase.x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.421333</td>\n",
       "      <td>But it is also memorable how Hamilton defined ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>0.273000</td>\n",
       "      <td>So in reviewing the replies I see a few others...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>0.321667</td>\n",
       "      <td>If you mean transitional between consecutive s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>0.248000</td>\n",
       "      <td>First, I wish to thank you for getting this th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0.132000</td>\n",
       "      <td>If there have been \"many\" cases why can't you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GoodSliderMean                                           Phrase.x\n",
       "986         0.421333  But it is also memorable how Hamilton defined ...\n",
       "1276        0.273000  So in reviewing the replies I see a few others...\n",
       "1114        0.321667  If you mean transitional between consecutive s...\n",
       "1311        0.248000  First, I wish to thank you for getting this th...\n",
       "959         0.132000  If there have been \"many\" cases why can't you ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = raw_data[\"Phrase.x\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_data[\"GoodSliderMean\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that encodes the sentences into usable vectors for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(sentences):\n",
    "    dataset = []\n",
    "    for i in range(len(sentences)):\n",
    "        # tokenize the sentence\n",
    "        tokens = nltk.word_tokenize(sentences[i])\n",
    "        # tag the all the tokens\n",
    "        pos_tokens = nltk.pos_tag(tokens)\n",
    "        # for each pos tag, count how many times it occurs in the sentence\n",
    "        pos_dict = generate_count_dict()\n",
    "        for tag in pos_tokens:\n",
    "            if tag[1] in pos_dict:\n",
    "                pos_dict[tag[1]] += 1\n",
    "        # get the pos tag counts as features \n",
    "        feature_vector = list(pos_dict.values())\n",
    "        dataset.append(feature_vector)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_count_dict():\n",
    "    tags = ['IN', 'PRP', 'VBP', 'TO', 'VB', 'JJ', 'NN', 'VBZ', 'VBN', 'DT', ',', 'NNP', 'VBD', '.']\n",
    "    dic = dict.fromkeys(tags, 0)\n",
    "    return dic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = encode_sentences(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a MLP on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(dataset, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20559518499098794"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
