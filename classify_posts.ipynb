{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\paul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import keras\n",
    "import numpy as np\n",
    "from CMVwebscraper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Google's word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format ('models/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec.similarity(\"cat\", \"dog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in our own Keras LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"models/bilstm_cos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model(\"models/bilstm_evidence.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.models.load_model(\"models/argument_quality.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def encode_post(sentences, topic):\n",
    "    # given a list of sentences and the topic that the sentences\n",
    "    # are related to, encode the sentences using the word2vec model\n",
    "    # and compute the similarity of each word to the topic as\n",
    "    # an additional feature for each word\n",
    "    encoded_sentences = []\n",
    "    \n",
    "    # compute the average word vector of the topic, so that each word\n",
    "    # from the sentences can be compared to the topic\n",
    "    topic_words = topic.split()\n",
    "    topic_word_vectors = []\n",
    "    for word in topic_words:\n",
    "        # check if the word exists in the word2vec dictionary\n",
    "        if(word in word2vec):\n",
    "                word_vector = word2vec[word]\n",
    "         # else, map the word to a random, 300-dimensional vector\n",
    "        else:\n",
    "            word_vector = np.random.uniform(low = -0.01, high = 0.01, size = (300))\n",
    "        topic_word_vectors.append(word_vector)\n",
    "    topic_word_vectors = np.asarray(topic_word_vectors)\n",
    "    # the average topic vector is the average of all the words in it, along each f\n",
    "    # the 300 dimensions\n",
    "    avg_topic_vector = np.mean(topic_word_vectors, axis = 0)\n",
    "      \n",
    "    # for every sentence in the post...\n",
    "    for i in range(len(sentences)):\n",
    "        # get the words of the sentence by means of tokanization\n",
    "        # discarding punctuation marks\n",
    "        words = []\n",
    "        tokens = nltk.word_tokenize(sentences[i])\n",
    "        for token in tokens:\n",
    "            # only append actual words\n",
    "            if(token[0] not in \".,:;[](){}!?-_`'~\\\"^/1234567890\"):\n",
    "                words.append(token)\n",
    "                \n",
    "        # store the word vectors into a sentence list\n",
    "        encoded_sentence = []\n",
    "                \n",
    "        # turn the words into word vectors\n",
    "        for word in words:\n",
    "            # check if the word exists in the word2vec dictionary\n",
    "            if(word in word2vec):\n",
    "                    word_vector = word2vec[word]\n",
    "             # else, map the word to a random, 300-dimensional vector\n",
    "            else:\n",
    "                word_vector = np.random.uniform(low = -0.01, high = 0.01, size = (300))\n",
    "        \n",
    "            # compute similarity between word and topic, then add this as the \n",
    "            # 301-th feature\n",
    "            similarity = cosine_similarity([word_vector], [avg_topic_vector])\n",
    "            word_vector = np.append(word_vector, similarity) \n",
    "            # add word to sentence list\n",
    "            encoded_sentence.append(word_vector)\n",
    "        encoded_sentence = np.asarray(encoded_sentence)\n",
    "        encoded_sentences.append(encoded_sentence)\n",
    "    # add encoded sentence to list of sentences      \n",
    "    encoded_sentences = np.asarray(encoded_sentences)\n",
    "        \n",
    "    return encoded_sentences\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_arguments(model, post, topic):\n",
    "    # split text into sentences\n",
    "    post_sentences = post.split(\".\")\n",
    "    # encode the sentences\n",
    "    encoded_sentences = encode_post(post_sentences, topic)\n",
    "     \n",
    "    # create lists to store the classified arguments and non-arguments\n",
    "    arguments = []\n",
    "    non_arguments = []\n",
    "    \n",
    "    #print(len(post_sentences), len(encoded_sentences))\n",
    "    #print(encoded_sentences[0])\n",
    "    #print(encoded_sentences[1])\n",
    "    \n",
    "    # feed sentences into LSTM and get prediction\n",
    "    for i in range(len(encoded_sentences)):\n",
    "        n_words = encoded_sentences[i].shape[0]\n",
    "        # skip empty sentences\n",
    "        if(n_words > 0):\n",
    "            n_features = encoded_sentences[i].shape[1]\n",
    "            prediction = model.predict(encoded_sentences[i].reshape(1, n_words, n_features), batch_size=1, verbose=0)\n",
    "            if(prediction > 0.5):\n",
    "                arguments.append((i, prediction, post_sentences[i]))\n",
    "            else:\n",
    "                non_arguments.append((i, prediction, post_sentences[i]))\n",
    "        else:\n",
    "             non_arguments.append((i, prediction, post_sentences[i]))\n",
    "            \n",
    "    return arguments, non_arguments, encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPname, OPtxt, CommentText, commentName, URL, TOPIC = search(\"Society\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Society does not need to change how it treats gender'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic = TOPIC.split(\":\")[1]\n",
    "topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Astrology and horoscopes makes no sense. It is statistically innacurate to describe people’s traits based on their birth date and time. Theres no valid science behind it. It makes absolutely no sense to read daily horoscopes in newspapers. There is no rational way to explain how 1/12 of the population will inexplicably “meet the woman of your dreams” the same day. It is just smoke and mirrors. The people who write that nonsense basically overshoot and try to layout multiple guesses for gullible people to believe. Most the time it doesn’t hit anything and when it does most people are like “OMG! How did he knew!?” and right away completely ignore that 99% of the time it is wrong.I also hate it when people ask my sign and when I tell them usually (specially women) put this face like “oh I figured!” And they frame me into a stupid stereotype.I think people take it for granted that astrology is a fact, and never stop to think about it.I won’t tell you my sun sign. Want to guess?Edit: I may sound a bit upset, but it is not my intention.Edit #2: some people have suggested to say “false” instead of “fake”. I do agree false may be more appropiate/precise in the sense of holding truth. Does not change much the intention of the idea.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#topic = \"People who stay behind and try to ride out a hurricane, and later need to be rescued, should be billed for the cost of their rescue unless they can prove that they either had to stay for work or didn't have the means to leave.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "OP_post = OPtxt\n",
    "OP_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments, non_arguments, encoded_sentences = detect_arguments(model, OP_post, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  array([[0.7049375]], dtype=float32),\n",
       "  ' It is statistically innacurate to describe people’s traits based on their birth date and time'),\n",
       " (4,\n",
       "  array([[0.9655996]], dtype=float32),\n",
       "  ' There is no rational way to explain how 1/12 of the population will inexplicably “meet the woman of your dreams” the same day')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  array([[0.00327707]], dtype=float32),\n",
       "  'Astrology and horoscopes makes no sense'),\n",
       " (2,\n",
       "  array([[0.1595855]], dtype=float32),\n",
       "  ' Theres no valid science behind it'),\n",
       " (3,\n",
       "  array([[0.00989058]], dtype=float32),\n",
       "  ' It makes absolutely no sense to read daily horoscopes in newspapers'),\n",
       " (5, array([[0.48778975]], dtype=float32), ' It is just smoke and mirrors'),\n",
       " (6,\n",
       "  array([[0.18074086]], dtype=float32),\n",
       "  ' The people who write that nonsense basically overshoot and try to layout multiple guesses for gullible people to believe'),\n",
       " (7,\n",
       "  array([[0.14279671]], dtype=float32),\n",
       "  ' Most the time it doesn’t hit anything and when it does most people are like “OMG! How did he knew!?” and right away completely ignore that 99% of the time it is wrong'),\n",
       " (8,\n",
       "  array([[0.02493911]], dtype=float32),\n",
       "  'I also hate it when people ask my sign and when I tell them usually (specially women) put this face like “oh I figured!” And they frame me into a stupid stereotype'),\n",
       " (9,\n",
       "  array([[0.10822597]], dtype=float32),\n",
       "  'I think people take it for granted that astrology is a fact, and never stop to think about it'),\n",
       " (10, array([[0.02517777]], dtype=float32), 'I won’t tell you my sun sign'),\n",
       " (11,\n",
       "  array([[0.02731409]], dtype=float32),\n",
       "  ' Want to guess?Edit: I may sound a bit upset, but it is not my intention'),\n",
       " (12,\n",
       "  array([[0.09897254]], dtype=float32),\n",
       "  'Edit #2: some people have suggested to say “false” instead of “fake”'),\n",
       " (13,\n",
       "  array([[0.05661781]], dtype=float32),\n",
       "  ' I do agree false may be more appropiate/precise in the sense of holding truth'),\n",
       " (14,\n",
       "  array([[0.01885292]], dtype=float32),\n",
       "  ' Does not change much the intention of the idea'),\n",
       " (15, array([[0.01885292]], dtype=float32), '')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def claim_or_evidence(model, arguments, sentences, encoded_sentences):\n",
    "    sentences = sentences.split(\".\")\n",
    "    # classify every argument as evidence or claim\n",
    "    classified_arguments = []\n",
    "    for arg in arguments:\n",
    "        # take the index from the tuple\n",
    "        idx = arg[0]\n",
    "        # take the encoded sentence corresponding to this\n",
    "        # argument\n",
    "        encoded_sentence = encoded_sentences[idx]\n",
    "       \n",
    "        n_words = encoded_sentence.shape[0]\n",
    "        n_features = encoded_sentence.shape[1]\n",
    "        score = model.predict(encoded_sentence.reshape(1, n_words, n_features), batch_size=1, verbose=0)\n",
    "        print(score[0])\n",
    "        # the LSTM is trained on discriminating between evidence sentences and non-evidence sentenves\n",
    "        # ASSUMPTION: if the argument is not an evidence sentence, it's a claim sentence\n",
    "        if(score >= 0.5):\n",
    "            classified_arguments.append((score[0], \"EVIDENCE\", sentences[idx]))\n",
    "        else:\n",
    "            classified_arguments.append((score[0], \"CLAIM\", sentences[idx]))\n",
    "    return classified_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00424341]\n",
      "[0.00402689]\n"
     ]
    }
   ],
   "source": [
    "classified_arguments = claim_or_evidence(model2, arguments, OP_post, encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0.00424341], dtype=float32),\n",
       "  'CLAIM',\n",
       "  ' It is statistically innacurate to describe people’s traits based on their birth date and time'),\n",
       " (array([0.00402689], dtype=float32),\n",
       "  'CLAIM',\n",
       "  ' There is no rational way to explain how 1/12 of the population will inexplicably “meet the woman of your dreams” the same day')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_argument_quality(model, arguments, sentences, encoded_sentences):\n",
    "    sentences = sentences.split(\".\")\n",
    "    # score each argument\n",
    "    for arg in arguments:\n",
    "        # take the index from the tuple\n",
    "        idx = arg[0]\n",
    "        # take the encoded sentence corresponding to this\n",
    "        # argument\n",
    "        encoded_sentence = encoded_sentences[idx]\n",
    "\n",
    "        n_words = encoded_sentence.shape[0]\n",
    "        n_features = encoded_sentence.shape[1]\n",
    "        score = model.predict(encoded_sentence.reshape(1, n_words, n_features), batch_size=1, verbose=0)\n",
    "        print(score[0], sentences[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70816755]  It is statistically innacurate to describe people’s traits based on their birth date and time\n",
      "[0.61725944]  There is no rational way to explain how 1/12 of the population will inexplicably “meet the woman of your dreams” the same day\n"
     ]
    }
   ],
   "source": [
    "get_argument_quality(model3, arguments, OP_post, encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
