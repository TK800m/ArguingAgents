{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\paul\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format ('models/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"models/bilstm_cos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_arguments(model, post):\n",
    "    # split text into sentences\n",
    "    post_sentences = post.split(\".\")\n",
    "    # count amount of sentences\n",
    "    n_sentences = len(post_sentences)\n",
    "    # add topic\n",
    "    topics = pd.Series([\"no topic\"] * (n_sentences), name = \"topic\")\n",
    "    # make data ready for encoding\n",
    "    sentences = pd.DataFrame(post_sentences)\n",
    "    df = pd.concat([sentences, topics], axis = 1)\n",
    "    df = df.rename(index=str, columns={0: \"sentence\"})\n",
    "    encoded_sentences, _ =  embed_sentences(sentences, len(sentences), topics)\n",
    "    \n",
    "    arguments = []\n",
    "    non_arguments = []\n",
    "    \n",
    "    # feed sentences into LSTM and get prediction\n",
    "    for i in range(len(encoded_sentences)):\n",
    "        n_words = encoded_sentences[i].shape[0]\n",
    "        if(n_words > 0):\n",
    "            n_features = encoded_sentences[i].shape[1]\n",
    "            prediction = model.predict(encoded_sentences[i].reshape(1, n_words, n_features), batch_size=1, verbose=0)\n",
    "            if(prediction > 0.5):\n",
    "                arguments.append((prediction, post_sentences[i]))\n",
    "            else:\n",
    "                non_arguments.append((prediction, post_sentences[i]))\n",
    "    return arguments, non_arguments      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
