{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from detect_and_score import *\n",
    "from scraper import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the word2vec model\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the argument quality model\n",
    "score_model = keras.models.load_model(\"models/argument_quality.h5\")\n",
    "detect_model = keras.models.load_model(\"models/bilstm_cos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract reddit topics with posts\n",
    "reddit_data = makeDF(range(0, 300, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report amount of proper topics found\n",
    "print(\"Amount of topics:\", len(reddit_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "def test_on_reddit(detect_model, threshold, score_model, reddit_data, print_results = False):\n",
    "\n",
    "    topic_accuracies = []\n",
    "    all_topics = []\n",
    "    for i in range(len(reddit_data)):\n",
    "        print(\"---------------------------Processing topic: {0}-----------------------------------\".format(i))\n",
    "        # get the delta posts\n",
    "        delta_posts = reddit_data[i][3]\n",
    "        normal_posts = reddit_data[i][2]\n",
    "        n_delta_posts = len(delta_posts)\n",
    "        # get the normal posts, WITHOUT the delta posts\n",
    "        normal_posts_filtered = []\n",
    "        for normal_post in normal_posts:\n",
    "            is_delta = False\n",
    "            for delta_post in delta_posts:\n",
    "                if(normal_post == delta_post):\n",
    "                    is_delta = True\n",
    "\n",
    "            if(is_delta == False):\n",
    "                normal_posts_filtered.append(normal_post)\n",
    "\n",
    "        n_normal_posts = len(normal_posts_filtered)     \n",
    "\n",
    "        # get topic and store for later\n",
    "        topic = reddit_data[i][0]\n",
    "        # score normal posts\n",
    "        normal_scores = []\n",
    "\n",
    "        for post in normal_posts_filtered:\n",
    "            score = detect_and_score(detect_model, threshold, score_model, post, topic, word2vec, print_results)\n",
    "            normal_scores.append(score)\n",
    "    \n",
    "        print(\"Normal post scores:\", normal_scores)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \"\"\"delta_posts = []\n",
    "        rand_idx = randrange(0, len(normal_posts_filtered))\n",
    "        delta_posts.append(normal_posts_filtered[rand_idx])\"\"\"\n",
    "        \n",
    "\n",
    "           \n",
    "        \n",
    "        \n",
    "        # score delta posts\n",
    "        delta_scores = []\n",
    "        for post in delta_posts:\n",
    "            score = detect_and_score(detect_model, threshold, score_model, post, topic, word2vec, print_results)\n",
    "            delta_scores.append(score)\n",
    "            \n",
    "        print(\"Delta post scores:\", delta_scores)\n",
    "\n",
    "        # check for each delta post how many normal scores are lower than its own score\n",
    "        total_accuracy = 0\n",
    "        for delta_score in delta_scores:\n",
    "            correct = 0\n",
    "            for normal_score in normal_scores:\n",
    "                if(delta_score > normal_score):\n",
    "                    correct += 1\n",
    "\n",
    "            accuracy = correct / n_normal_posts\n",
    "            \n",
    "                \n",
    "            total_accuracy += accuracy\n",
    "        total_accuracy /= n_delta_posts\n",
    "\n",
    "        print(\"Topic\", i, \":\", total_accuracy)\n",
    "        all_topics.append(topic)\n",
    "        topic_accuracies.append(total_accuracy)\n",
    "    return topic_accuracies, all_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    print(\"--------------------------------threshold = {0}---------------------------------------------\".format(threshold))\n",
    "    topic_accuracies, all_topics = test_on_reddit(detect_model, threshold, score_model, reddit_data)\n",
    "    mean = np.mean(np.array(topic_accuracies))\n",
    "    variance = np.var(np.array(topic_accuracies))\n",
    "    print(\"Mean Accuracy: {0} \\n Variance: {1}\".format(mean, variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topic_accuracies, all_topics = test_on_reddit(detect_model, 0.1, score_model, reddit_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topic_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(range(len(topic_accuracies)), topic_accuracies)\n",
    "plt.xlabel(\"Topic\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Mean topic accuracy, threshold = 0.1\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
