{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate and inspect the combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_abo = pd.read_csv(\"data/abortion.tsv\", sep = \"\\t\")\n",
    "raw_data_clo = pd.read_csv(\"data/cloning.tsv\", sep = \"\\t\")\n",
    "raw_data_dp = pd.read_csv(\"data/death_penalty.tsv\", sep = \"\\t\") \n",
    "raw_data_gun = pd.read_csv(\"data/gun_control.tsv\", sep = \"\\t\")\n",
    "raw_data_mari = pd.read_csv(\"data/marijuana_legalization.tsv\", sep = \"\\t\")\n",
    "raw_data_wage = pd.read_csv(\"data/minimum_wage.tsv\", sep = \"\\t\")\n",
    "raw_data_nuc = pd.read_csv(\"data/nuclear_energy.tsv\", sep = \"\\t\")\n",
    "raw_data_school = pd.read_csv(\"data/school_uniforms.tsv\", sep = \"\\t\", quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [raw_data_abo, raw_data_clo, raw_data_dp, raw_data_gun, raw_data_mari, raw_data_wage, raw_data_nuc, raw_data_school]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.concat(frames, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined dataset contains 24507 rows and 7 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The combined dataset contains {0} rows and {1} columns\".format(len(raw_data), len(raw_data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data[[\"sentence\", \"annotation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This means it has to steer monetary policy to ...</td>\n",
       "      <td>NoArgument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where did you get that ?</td>\n",
       "      <td>NoArgument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nathanson later became pro-life .</td>\n",
       "      <td>NoArgument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this case we may never do evil ( directly a...</td>\n",
       "      <td>Argument_against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>With that I would like to give everyone someth...</td>\n",
       "      <td>NoArgument</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence        annotation\n",
       "0  This means it has to steer monetary policy to ...        NoArgument\n",
       "1                           Where did you get that ?        NoArgument\n",
       "2                  Nathanson later became pro-life .        NoArgument\n",
       "3  In this case we may never do evil ( directly a...  Argument_against\n",
       "4  With that I would like to give everyone someth...        NoArgument"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the features in an appropriate form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_POS_dict(sentences):\n",
    "    # extract all the occurring parts-of-speech tags that occur in the corpus\n",
    "    pos_dict = {}\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        # tokenize and pos tag \n",
    "        tokens = nltk.word_tokenize(sentences[i])\n",
    "        pos_tokens = nltk.pos_tag(tokens)\n",
    "        for token in pos_tokens:\n",
    "            if(token[1] not in pos_dict):\n",
    "                pos_dict[token[1]] = 0\n",
    "    return pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def generate_BOW_dict(sentences):\n",
    "    # extract all the occurring words in the corpus\n",
    "    bow_dict = {}\n",
    "    for i in range(len(sentences)):\n",
    "        #tokenize the sentence\n",
    "        tokens = nltk.word_tokenize(sentences[i])\n",
    "        for token in tokens:\n",
    "            # count how many times a word occurs in the texts\n",
    "            if(token.lower() in bow_dict):\n",
    "                bow_dict[token.lower()] += 1 \n",
    "            # add a new word if it's not a stopword or a punctuation mark\n",
    "            elif(token.lower() not in stopwords.words('English') and token.lower()[0] not in [\".,:;!?<>{}()1234567890\"]):\n",
    "                bow_dict[token.lower()] = 1\n",
    "                \n",
    "    # filter out the words that barely occur\n",
    "    frequency_threshold = 5\n",
    "    dict_size = len(bow_dict)\n",
    "    words = []\n",
    "    for key in bow_dict:\n",
    "        if(bow_dict[key] < frequency_threshold):\n",
    "            words.append(key)\n",
    "    \n",
    "    for word in words:\n",
    "        bow_dict.pop(word, None)\n",
    "        \n",
    "    \n",
    "                \n",
    "    return bow_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def normalize(data):\n",
    "    # this function applies min-max scaling to a given dataframe\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences(sentences, pos_dict, bow_dict):\n",
    "    dataset = []\n",
    "    for i in range(len(sentences)):\n",
    "        # reset POS and word counts for each sentence\n",
    "        pos_dict = pos_dict.fromkeys(pos_dict, 0)\n",
    "        bow_dict = pos_dict.fromkeys(bow_dict, 0)\n",
    "        # tokenize the sentence\n",
    "        tokens = nltk.word_tokenize(sentences[i])\n",
    "        # tag the all the tokens\n",
    "        pos_tokens = nltk.pos_tag(tokens)\n",
    "        # for each pos tag, count how many times it occurs in the sentence\n",
    "        for tag in pos_tokens:\n",
    "            if(tag[1] in pos_dict):\n",
    "                pos_dict[tag[1]] += 1\n",
    "        # get the pos tag counts as features \n",
    "        pos_vector = list(pos_dict.values())\n",
    "        \n",
    "        # count how many times the words from the bow dict occur in the sentence\n",
    "        for token in tokens:\n",
    "            if(token.lower() in bow_dict):\n",
    "                bow_dict[token.lower()] += 1\n",
    "        bow_vector = list(pos_dict.values())\n",
    "        \n",
    "        feature_vector = bow_vector + pos_vector\n",
    "        #feature_vector = pos_vector\n",
    "        # add sentence length as a feature\n",
    "        feature_vector.append(len(tokens))     \n",
    "        # compute the average word length of the sentence\n",
    "        n_chars = 0\n",
    "        avg_len = 0\n",
    "        for token in tokens:\n",
    "            if(token[0] not in \".,?!:;\"):\n",
    "                n_chars += len(token)\n",
    "        avg_len = n_chars / len(tokens)\n",
    "        feature_vector.append(avg_len)     \n",
    "        dataset.append(feature_vector)\n",
    "        \n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = raw_data.sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = generate_POS_dict(sentences.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_dict = generate_BOW_dict(sentences.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentences = encode_sentences(sentences.values, pos_dict, bow_dict)\n",
    "encoded_sentences = pd.DataFrame(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "def kfold(data, labels, folds, classifier):\n",
    "    kf = KFold(n_splits=folds)\n",
    "\n",
    "    avg_accuracy = 0\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        # reset the classifier\n",
    "        classifier = clone(classifier)\n",
    "        \n",
    "        \n",
    "        Xtrain = data[train_index]\n",
    "        Xtest = data[test_index]\n",
    "        \n",
    "        Ytrain = labels[train_index]\n",
    "        Ytest = labels[test_index]\n",
    "        \n",
    "        mlp.fit(Xtrain, Ytrain)\n",
    "        avg_accuracy += mlp.score(Xtest, Ytest)\n",
    "\n",
    "    avg_accuracy /= folds\n",
    "    print(\"{0}-fold cross validation accuracy: {1}\".format(folds, avg_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data = normalize(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_data.annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[labels == \"NoArgument\"] = 0\n",
    "labels[labels != 0] = 1\n",
    "labels = labels.values.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments:  0.4374668462072061\n",
      "Amount of non-arguments:  0.5625331537927939\n"
     ]
    }
   ],
   "source": [
    "arguments = labels[labels == 1]\n",
    "non_arguments = labels[labels == 0]\n",
    "n_arg = len(arguments)\n",
    "n_non = len(non_arguments)\n",
    "print(\"Arguments: \", n_arg / (n_arg + n_non))\n",
    "print(\"Amount of non-arguments: \", n_non / (n_arg + n_non))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the normalized data that's going to be fed to the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence dimensions: 92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.02222222, 0.01973684, 0.01769912, 0.00680272, 0.02439024,\n",
       "       0.00406504, 0.01265823, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02222222, 0.01973684, 0.01769912, 0.00680272, 0.02439024,\n",
       "       0.00406504, 0.01265823, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00465333, 0.39328939])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sentence dimensions:\", len(sentence_data[0]))\n",
    "sentence_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#mlp = MLPRegressor()\n",
    "#lr = LinearRegression()\n",
    "#rf = RandomForestRegressor()\n",
    "mlp = MLPClassifier(max_iter = 300)\n",
    "lr = LogisticRegression(max_iter = 300)\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test different sklearn classifiers with k-folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation accuracy: 0.6605456001077558\n"
     ]
    }
   ],
   "source": [
    "\"\"\"lrs = [0.1, 0.01, 0.001, 0.0001]\n",
    "hl = [50, 100, 250, 500]\n",
    "for learning_rate in lrs:\n",
    "    for n_hidden in hl:\n",
    "        mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (n_hidden,), alpha = learning_rate)\n",
    "        print(\"-----------------Setting: lr: {0} hl: {1}----------------------\".format(learning_rate, n_hidden))\n",
    "        kfold(sentence_data, labels.values, 5, mlp)\"\"\"\n",
    "kfold(sentence_data, labels, 5, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation accuracy: 0.6625453918221338\n"
     ]
    }
   ],
   "source": [
    "kfold(sentence_data, labels, 5, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation accuracy: 0.660953846586734\n"
     ]
    }
   ],
   "source": [
    "kfold(sentence_data, labels, 5, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit classifier on the train data normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter = 300, hidden_layer_sizes = (250,), alpha = 0.1)\n",
    "lr = LogisticRegression(max_iter = 300)\n",
    "rf = RandomForestClassifier()\n",
    "#mlp = MLPRegressor(max_iter = 300, hidden_layer_sizes = (250,), alpha = 0.1)\n",
    "#lr = LinearRegression()\n",
    "#rf = RandomForestRegressor()\n",
    "\n",
    "\n",
    "\n",
    "mlp.fit(sentence_data, labels)\n",
    "lr.fit(sentence_data, labels)\n",
    "rf.fit(sentence_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test how the models score arguments taken from Reddit posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_post(text, pos_dict, bow_dict, classifier):\n",
    "    # given a text, the feature vector will be built just like in the training stage\n",
    "    # the classifier will then be applied to the sentences and score the arguments within\n",
    "    sentences = text.split('.')[:-1] \n",
    "    # get the POS and BOW encodings for each sentence\n",
    "    encoded_sentences = encode_sentences(sentences, pos_dict, bow_dict)\n",
    "    encoded_sentences = pd.DataFrame(encoded_sentences)\n",
    "    # scale features between 0 and 1 using Min-Max scaling\n",
    "    encoded_sentences = normalize(encoded_sentences)\n",
    "\n",
    "    filtered_text = []\n",
    "    removed_sentences = []\n",
    "    for i in range(len(encoded_sentences)):\n",
    "        if(len(sentences[i].split()) < 5):\n",
    "            removed_sentences.append((0, sentences[i]))\n",
    "        else:\n",
    "            score = classifier.predict_proba([encoded_sentences[i]])[0][1]\n",
    "            if(score >= 0.5):     \n",
    "                filtered_text.append((score, sentences[i]))\n",
    "            else:\n",
    "                removed_sentences.append((score, sentences[i]))\n",
    "\n",
    "    print(\"{0} filtered from the input text!\".format(len(removed_sentences)))\n",
    "    return filtered_text, removed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Shape of Water is an extremely overrated movie and should have never won the Oscar for Best Picture I recently rewatched The Shape of Water and I am not a movie critique nor expert, but the realization dawned on me that it is an exquisitely bland movie that lacks an absurd amount of substance. The Shape of Water plays on to the basic beauty and the beast trope, but it does not go any further than that. The movie weighs heavily on the cinematography and strays away from any actual plot or substance. It is an intermediate form of movie writing and does not deserve any more than a Redbox rental. The movie barely dives into the actual underlying foundation for why anything happens, there is no room for individual thought and it is pressed into the viewer’s brain that there is only one way to think and that is with the protagonist. According to Vox, It’s a beautifully shot movie with a story that follows the traditional arcs of a fairy tale romance. I believe that it is exactly why it should not have won, it has been done before. Compared to other past winners, such as Moonlight, which was original and intriguing. There is no relevance to the Shape of Water, no bigger picture. A mute woman falls in love with a sea creature who likes eggs. If that’s the precedent for winning an Oscar, then The Leprechaun would have been a phenomenal candidate. The movie is visually outstanding, but so is The Curious Case of Benjamin Button and it is an incredibly lifeless movie starring Brad Pitt! Without the visuals the movie would merely be a pathetic case for an “original” plot. Quite honestly, coming from Guillermo del Toro I would not expect much, all of his movies rely on visuals such as Crimson Peak or The Hobbit. These movies appeal to the eye and the only Oscar that this movie truly deserved was Best Visuals. Overall, the movie is basic with jaw dropping visuals. The movie won four Oscars, so it is obviously well received and I’d like to understand what is so special about its standard format. Change my view!!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OP = \"The Shape of Water is an extremely overrated movie and should have never won the Oscar for Best Picture I recently rewatched The Shape of Water and I am not a movie critique nor expert, but the realization dawned on me that it is an exquisitely bland movie that lacks an absurd amount of substance. The Shape of Water plays on to the basic beauty and the beast trope, but it does not go any further than that. The movie weighs heavily on the cinematography and strays away from any actual plot or substance. It is an intermediate form of movie writing and does not deserve any more than a Redbox rental. The movie barely dives into the actual underlying foundation for why anything happens, there is no room for individual thought and it is pressed into the viewer’s brain that there is only one way to think and that is with the protagonist. According to Vox, It’s a beautifully shot movie with a story that follows the traditional arcs of a fairy tale romance. I believe that it is exactly why it should not have won, it has been done before. Compared to other past winners, such as Moonlight, which was original and intriguing. There is no relevance to the Shape of Water, no bigger picture. A mute woman falls in love with a sea creature who likes eggs. If that’s the precedent for winning an Oscar, then The Leprechaun would have been a phenomenal candidate. The movie is visually outstanding, but so is The Curious Case of Benjamin Button and it is an incredibly lifeless movie starring Brad Pitt! Without the visuals the movie would merely be a pathetic case for an “original” plot. Quite honestly, coming from Guillermo del Toro I would not expect much, all of his movies rely on visuals such as Crimson Peak or The Hobbit. These movies appeal to the eye and the only Oscar that this movie truly deserved was Best Visuals. Overall, the movie is basic with jaw dropping visuals. The movie won four Oscars, so it is obviously well received and I’d like to understand what is so special about its standard format. Change my view!!\"\n",
    "OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 filtered from the input text!\n"
     ]
    }
   ],
   "source": [
    "good, bad = score_post(OP, pos_dict, bow_dict, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9189520379966982,\n",
       "  ' The Shape of Water plays on to the basic beauty and the beast trope, but it does not go any further than that'),\n",
       " (0.9264363585159258,\n",
       "  ' The movie weighs heavily on the cinematography and strays away from any actual plot or substance'),\n",
       " (0.9626864491377539,\n",
       "  ' It is an intermediate form of movie writing and does not deserve any more than a Redbox rental'),\n",
       " (0.9152930644592397,\n",
       "  ' The movie barely dives into the actual underlying foundation for why anything happens, there is no room for individual thought and it is pressed into the viewer’s brain that there is only one way to think and that is with the protagonist'),\n",
       " (0.9581909466888983,\n",
       "  ' According to Vox, It’s a beautifully shot movie with a story that follows the traditional arcs of a fairy tale romance'),\n",
       " (0.9339069461317748,\n",
       "  ' I believe that it is exactly why it should not have won, it has been done before'),\n",
       " (0.7621645142307019,\n",
       "  ' Compared to other past winners, such as Moonlight, which was original and intriguing'),\n",
       " (0.9126546044060165,\n",
       "  ' There is no relevance to the Shape of Water, no bigger picture'),\n",
       " (0.7867657326040625,\n",
       "  ' A mute woman falls in love with a sea creature who likes eggs'),\n",
       " (0.9978648005557094,\n",
       "  ' If that’s the precedent for winning an Oscar, then The Leprechaun would have been a phenomenal candidate'),\n",
       " (0.9550227681681619,\n",
       "  ' The movie is visually outstanding, but so is The Curious Case of Benjamin Button and it is an incredibly lifeless movie starring Brad Pitt! Without the visuals the movie would merely be a pathetic case for an “original” plot'),\n",
       " (0.985649374826771,\n",
       "  ' Quite honestly, coming from Guillermo del Toro I would not expect much, all of his movies rely on visuals such as Crimson Peak or The Hobbit'),\n",
       " (0.8408432550198763,\n",
       "  ' These movies appeal to the eye and the only Oscar that this movie truly deserved was Best Visuals'),\n",
       " (0.9797791492307205,\n",
       "  ' Overall, the movie is basic with jaw dropping visuals'),\n",
       " (0.6465549361722047,\n",
       "  ' The movie won four Oscars, so it is obviously well received and I’d like to understand what is so special about its standard format')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.39199134959779175,\n",
       "  'The Shape of Water is an extremely overrated movie and should have never won the Oscar for Best Picture I recently rewatched The Shape of Water and I am not a movie critique nor expert, but the realization dawned on me that it is an exquisitely bland movie that lacks an absurd amount of substance')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The root problem is gendered dresscodes. When men are expected to suit up, you have to put the temperature down quite a bit, because suits are hot. But a women's suit typically has an open neckline and a knee length shirt. For women in office wear, you have to put the temperature way up because they lose a lot more warmth. There is no compromise possible because neither gender is allowed to put on more or less clothing under typical dress codes. Either make dress codes similar for all employees or remove dress codes altogether so that everyone can wear what's appropriate for whatever temperature the janitor set.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = \"The root problem is gendered dresscodes. When men are expected to suit up, you have to put the temperature down quite a bit, because suits are hot. But a women's suit typically has an open neckline and a knee length shirt. For women in office wear, you have to put the temperature way up because they lose a lot more warmth. There is no compromise possible because neither gender is allowed to put on more or less clothing under typical dress codes. Either make dress codes similar for all employees or remove dress codes altogether so that everyone can wear what's appropriate for whatever temperature the janitor set.\"\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 filtered from the input text!\n"
     ]
    }
   ],
   "source": [
    "good, bad = score_post(counter, pos_dict, bow_dict, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.854478913433192, 'The root problem is gendered dresscodes'),\n",
       " (0.9663238781116106,\n",
       "  ' When men are expected to suit up, you have to put the temperature down quite a bit, because suits are hot'),\n",
       " (0.518143107282184,\n",
       "  \" But a women's suit typically has an open neckline and a knee length shirt\"),\n",
       " (0.984656442615816,\n",
       "  ' For women in office wear, you have to put the temperature way up because they lose a lot more warmth'),\n",
       " (0.9971307758850677,\n",
       "  ' There is no compromise possible because neither gender is allowed to put on more or less clothing under typical dress codes'),\n",
       " (0.9994575524702001,\n",
       "  \" Either make dress codes similar for all employees or remove dress codes altogether so that everyone can wear what's appropriate for whatever temperature the janitor set\")]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
