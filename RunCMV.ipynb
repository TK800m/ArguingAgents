{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CMVscraper_script_delta import *\n",
    "import pandas as pd\n",
    "my_data= []\n",
    "\n",
    "#OPname, OPtxt, CommentText, commentName, URL, TOPIC, deltalink, deltabot= search(\"people\")\n",
    "\n",
    "\n",
    "def makeDF(post_range, filename):\n",
    "    my_data_log = []\n",
    "    for num in post_range:\n",
    "        if num != 20:\n",
    "            OPname, OPtxt, CommentText, commentName, URL, TOPIC, deltalink, deltabot= urlSearch(num)\n",
    "            if deltalink != None and len(deltalink) >0:\n",
    "                print(str(num) + \") found a delta in: \"+ URL)\n",
    "                deltaNames, deltapost, delta_urls = getDeltaNames(deltalink, deltabot, CommentText)\n",
    "                #print(deltaComments)\n",
    "                #deltapost = find_delta_txt(deltaNames, deltaComments, CommentText, commentName)\n",
    "                easyOP = flesch_ease_OP(OPtxt)\n",
    "                \n",
    "                easyComm = []\n",
    "                for x in range(len(deltapost)):\n",
    "                    easyComm.append(flesch_ease_comm(CommentText))\n",
    "                my_data_log.append([OPname, OPtxt, commentName,CommentText,  URL, TOPIC, deltalink, deltaNames, deltapost, easyOP, easyComm])\n",
    "            else:\n",
    "                  print(str(num) + \") no delta found in: \"+ TOPIC)\n",
    "    filename= 'cmv_'+str(filename)+'.csv'\n",
    "    pd.DataFrame(my_data_log, columns=['op_name','op_text','comment_name', 'comment_text', 'url', 'topic', 'delta_link', 'delta_names', 'delta_text', 'op_easy_score', 'delta_easy_score']).to_csv(filename)\n",
    "    return(my_data_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDF(post_range):\n",
    "    my_data_log = []\n",
    "    for num in post_range:\n",
    "        if num != 20:\n",
    "            OPname, OPtxt, CommentText, commentName, URL, TOPIC, deltalink, deltabot= urlSearch(num)\n",
    "            if deltalink != None and len(deltalink) >0:\n",
    "                print(str(num) + \") found a delta in: \"+ URL)\n",
    "                deltaNames, deltapost, delta_urls = getDeltaNames(deltalink, deltabot, CommentText)\n",
    "                #print(deltaComments)\n",
    "                #deltapost = find_delta_txt(deltaNames, deltaComments, CommentText, commentName)\n",
    "                easyOP = flesch_ease_OP(OPtxt)\n",
    "                \n",
    "                easyComm = []\n",
    "                for x in range(len(deltapost)):\n",
    "                    easyComm.append(flesch_ease_comm(CommentText))\n",
    "                my_data_log.append([OPname, OPtxt, commentName,CommentText,  URL, TOPIC, deltalink, deltaNames, deltapost, easyOP, easyComm])\n",
    "            else:\n",
    "                  print(str(num) + \") no delta found in: \"+ TOPIC)\n",
    "    return(my_data_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_manual_data = makeDF(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_manual_data = makeDF(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= 'cmv_0_to_100.csv'\n",
    "pd.DataFrame(my_manual_data, columns=['op_name','op_text','comment_name', 'comment_text', 'url', 'topic', 'delta_link', 'delta_names', 'delta_text', 'op_easy_score', 'delta_easy_score']).to_csv(filename)\n",
    "#my_data.append(my_manual_data)\n",
    "\n",
    "\n",
    "# not 20 to 23, 40,88,89,93,94,103,104,135,136\n",
    "#my_data = makeDF(range(0,50, 1),'0_to_50')\n",
    "#my_data2 = makeDF(range(50,100, 1), '51_to_100')\n",
    "#my_data3 = makeDF(range(101,150, 1), '101_to_150')\n",
    "print(len(my_data))\n",
    "#print(my_data2[0][7])\n",
    "#print(my_data2[0][8][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13) found a delta in: https://old.reddit.com/r/changemyview/comments/9pyolh/cmv_shelby_v_holder_is_a_bigger_example_of/\n",
      "16) found a delta in: https://old.reddit.com/r/changemyview/comments/9pzxe9/cmv_affirmative_action_should_not_be_a_thing_at/\n",
      "18) no delta found in: CMV: R/latestagecapitalism would be empty if economics were mandatory in schools.\n",
      "19) found a delta in: https://old.reddit.com/r/changemyview/comments/9q2t85/cmv_the_senate_handled_the_kavanaugh_confirmation/\n",
      "33) found a delta in: https://old.reddit.com/r/changemyview/comments/9pv90g/cmv_cabbage_is_superior_to_lettuce/\n",
      "37) found a delta in: https://old.reddit.com/r/changemyview/comments/9q1hi9/cmvif_corporations_are_people_they_should_be_able/\n",
      "38) found a delta in: https://old.reddit.com/r/changemyview/comments/9ptthd/cmv_george_orwell_is_the_greatest_english/\n",
      "44) found a delta in: https://old.reddit.com/r/changemyview/comments/9pzsun/cmv_millennials_can_afford_houses/\n",
      "48) found a delta in: https://old.reddit.com/r/changemyview/comments/9pu3nh/cmv_i_hated_my_academic_life/\n",
      "49) found a delta in: https://old.reddit.com/r/changemyview/comments/9pu3nh/cmv_i_hated_my_academic_life/\n",
      "50) found a delta in: https://old.reddit.com/r/changemyview/comments/9pyupa/cmv_the_houses_of_the_us_congress_should_not_be/\n",
      "54) found a delta in: https://old.reddit.com/r/changemyview/comments/9pnlvh/cmv_people_are_going_to_do_it_anyway_is_a_bad/\n",
      "57) found a delta in: https://old.reddit.com/r/changemyview/comments/9pb1fp/cmv_elizabeth_warrens_decision_to_release_her_dna/\n",
      "60) found a delta in: https://old.reddit.com/r/changemyview/comments/9ppm9u/cmv_legislatures_should_always_respect_the_will/\n",
      "61) found a delta in: https://old.reddit.com/r/changemyview/comments/9pz80g/cmv_cisgender_people_who_dont_meet_the_proper/\n",
      "62) found a delta in: https://old.reddit.com/r/changemyview/comments/9plwrs/cmv_an_ai_doomsday_scenario_will_not_happen/\n",
      "65) found a delta in: https://old.reddit.com/r/changemyview/comments/9pkrtf/cmv_hair_should_not_be_gendered/\n",
      "66) found a delta in: https://old.reddit.com/r/changemyview/comments/9pisur/cmv_zipup_onesies_should_have_the_zipper_rest_at/\n",
      "68) found a delta in: https://old.reddit.com/r/changemyview/comments/9pr1q6/cmv_the_state_should_start_regulating_procreation/\n",
      "70) found a delta in: https://old.reddit.com/r/changemyview/comments/9pr61n/cmvpeople_who_use_the_word_nani_when_they_arent/\n",
      "72) found a delta in: https://old.reddit.com/r/changemyview/comments/9p1ev6/cmv_people_should_stop_assuming_that_someone_in_a/\n",
      "75) found a delta in: https://old.reddit.com/r/changemyview/comments/9pc3hd/cmv_websites_should_not_have_mandatory/\n",
      "76) found a delta in: https://old.reddit.com/r/changemyview/comments/9pboti/cmv_i_hate_furries_because_the_furry_fandom_is_a/\n",
      "77) found a delta in: https://old.reddit.com/r/changemyview/comments/9pb55h/cmv_2018_uci_masters_champion_dr_rachel_mckinnon/\n",
      "78) found a delta in: https://old.reddit.com/r/changemyview/comments/9pa925/cmv_the_issue_of_abortion_from_a_morality/\n",
      "79) found a delta in: https://old.reddit.com/r/changemyview/comments/9pm63i/cmv_the_minimum_wage_should_be_abolished_it_is/\n",
      "85) found a delta in: https://old.reddit.com/r/changemyview/comments/9pblci/cmv_the_teenager_who_baked_her_grandfathers_ashes/\n",
      "86) found a delta in: https://old.reddit.com/r/changemyview/comments/9pb41n/cmv_health_insurrance_should_be_illegal_in_the_us/\n"
     ]
    }
   ],
   "source": [
    "arr =[13,16,18,19,33,37,38,44,48,49,50,54,57,60,61,62,65,66,68,70,72,75,76,77,78,79,85,86]\n",
    "for i in range(len(arr)):\n",
    "    arr[i] = arr[i]\n",
    "    \n",
    "my_manual_data = makeDF(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= 'cmv_0_to_100.csv'\n",
    "pd.DataFrame(my_manual_data, columns=['op_name','op_text','comment_name', 'comment_text', 'url', 'topic', 'delta_link', 'delta_names', 'delta_text', 'op_easy_score', 'delta_easy_score']).to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "[13, 16, 18, 19, 33, 37, 38, 44, 48, 49, 50, 54, 57, 60, 61, 62, 65, 66, 68, 70, 72, 75, 76, 77, 78, 79, 85, 86]\n"
     ]
    }
   ],
   "source": [
    "print(len(my_manual_data))\n",
    "\n",
    "#arr = [i for i in range(10,20)]\n",
    "#arr += [i for i in range(24,40)]+[i for i in range(41,88)]+[i for i in range(90,93)]+[i for i in range(95,103)]+[i for i in range(105,135)]\n",
    "#[OPname, OPtxt, commentName,CommentText,  URL, TOPIC, deltalink, deltaNames, deltapost, easyOP, easyComm]\n",
    "#for i in range(len(my_data)):\n",
    "#    print(my_data[i][4]) \n",
    "#    print(my_data[i][5])\n",
    "#    print(my_data[i][7])\n",
    "#    print(my_data[i][8])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDeltaNames(deltalink, deltabot, CommentText):\n",
    "    if deltabot == True:\n",
    "        deltaTXT = CommentText[0]\n",
    "        deltaW = deltaTXT.split()\n",
    "        deltaNumber = int(deltaTXT.split()[4])\n",
    "        #print(deltaW)\n",
    "        #print(deltaNumber)\n",
    "        #print(deltalink[0])\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    if deltalink != None:\n",
    "\n",
    "        url = deltalink[0]\n",
    "        store = []\n",
    "\n",
    "        comment_area = souper(url).find('div',attrs={'class':'commentarea'})\n",
    "        comments = comment_area.find_all('div', attrs={'class':'entry unvoted'})\n",
    "        for comment in comments: \n",
    "                if comment.find('form'):\n",
    "                    delta = comment.find('div', {'class': 'md'})\n",
    "                    if delta.find('a', {'href': True}, text='here')!= None:\n",
    "                        store.append(delta.find('a', {'href': True}, text='here'))\n",
    "\n",
    "        deltaurl = str(store[0])\n",
    "        #print(deltaurl)\n",
    "        remove_letters = len(deltaurl)\n",
    "        for i in range(len(deltaurl)):\n",
    "            if deltaurl[i] == \">\":\n",
    "                remove_letters-=i - 1\n",
    "                break\n",
    "\n",
    "        #print(remove_letters)\n",
    "\n",
    "        deltaurl = \"https://old.reddit.com\"+ deltaurl[9:-remove_letters]\n",
    "\n",
    "        #print(deltaurl)\n",
    "        #print(store)\n",
    "\n",
    "        store = []\n",
    "        main_table = souper(deltaurl).find(\"div\",attrs={'id':'siteTable'})\n",
    "        entries = main_table.find_all(\"div\",attrs={'class':'entry unvoted'})\n",
    "        #print(main_table)\n",
    "        #print(entries)\n",
    "        for entry in entries:\n",
    "            if entry.find('form'):\n",
    "                #print(entry.find('form'))\n",
    "                delta = entry.find('div', {'class': 'md'})\n",
    "                #print(delta)\n",
    "                allNames = delta.find_all('a', {'href': True})\n",
    "                comment_a_tags = delta.find_all('a',attrs={'href':True})\n",
    "                delta_urls = []\n",
    "                for a_tag in comment_a_tags:\n",
    "                    delta_url = a_tag['href']\n",
    "                    delta_urls.append(delta_url)\n",
    "        print(delta_urls)\n",
    "        deltanames = []\n",
    "        deltacomment = []\n",
    "        for i in range(4,4+deltaNumber*2,2):\n",
    "            #print(i)\n",
    "            deltanames.append(delta_urls[i])\n",
    "            deltacomment.append(\"https://old.reddit.com\"+delta_urls[i+1])\n",
    "            \n",
    "        deltanames, deltacomment = getdeltatext(deltacomment)\n",
    "        #print(deltanames)\n",
    "        #print(deltacomment)\n",
    "        return(deltanames, deltacomment, delta_urls)\n",
    "\n",
    "def getdeltatext(url):\n",
    "    name = []\n",
    "    text = []\n",
    "    for i in range(len(url)):\n",
    "        comment_area = souper(url[i]).find('div',attrs={'class':'commentarea'})\n",
    "        comments = comment_area.find_all('div', attrs={'class':'entry unvoted'})\n",
    "        textComm = ''\n",
    "        names = ''\n",
    "        for comment in comments: \n",
    "            if comment.find('form'):\n",
    "                commenter = comment.find('a',attrs={'class':'author'}).text\n",
    "                comment_text = comment.find('div',attrs={'class':'md'}).text\n",
    "                textComm = comment_text\n",
    "                names = commenter\n",
    "                if textComm != '' and names!= '':\n",
    "                    name.append(names)\n",
    "                    text.append(textComm)\n",
    "                    break\n",
    "    return(name, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPname, OPtxt, CommentText, commentName, URL, TOPIC, deltalink, deltabot= urlSearch(15)\n",
    "if deltalink != None and len(deltalink) >0:\n",
    "    print(\"found a delta in: \"+ URL)\n",
    "    deltaNames, deltaComments, delta_urls = getDeltaNames(deltalink, deltabot, CommentText)\n",
    "    print(deltaComments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deltaNames[1])\n",
    "print(deltaComments[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinOP = flesch_kincaid_OP(OPtxt)\n",
    "kinComm= flesch_kincaid_comm(CommentText)\n",
    "easyOP = flesch_ease_OP(OPtxt)\n",
    "easyComm = flesch_ease_comm(CommentText)\n",
    "\n",
    "#for some reason doesnt work but does below\n",
    "(similar, locsimilar) = similarEase(easyOP, easyComm, CommentText, commentName)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(similar, locsimilar) = similarEase(easyOP, easyComm, CommentText, commentName, OPname)\n",
    "detlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the list of similar\n",
    "similar, locsimilar = zip(*sorted(zip(similar, locsimilar)))\n",
    "print(similar)\n",
    "print(locsimilar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_txt = []\n",
    "op_txt = []\n",
    "for i in range(5):\n",
    "    OPname, OPtxt, CommentText, commentName, URL, TOPIC, deltalink, deltabot= urlSearch(i)\n",
    "    \n",
    "    if deltalink != None and len(deltalink) >0:\n",
    "        op_txt.append(OPtxt)\n",
    "        deltaNames, deltaComments = getDeltaNames(deltalink, deltabot, CommentText)\n",
    "        deltas_txt.append(find_delta_txt(deltaNames, deltaComments, CommentText, commentName))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### op_easy = flesch_ease_comm(op_txt)\n",
    "delta_easy = flesch_ease_comm(deltas_txt[4])\n",
    "\n",
    "print(delta_easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def urlSearch(query):\n",
    "#     import math\n",
    "#     page_number = math.floor(query/25)\n",
    "#     item = query-(page_number*25)-1\n",
    "#     url =  \"https://old.reddit.com/r/changemyview/\"\n",
    "#     if page_number <1:\n",
    "#         url = url\n",
    "#     else:\n",
    "#         for i in range(page_number):\n",
    "#             url = get_next_page(url)\n",
    "#     ##two vectors of topics and urls\n",
    "#     topics, urls = linksAndTopics(url)\n",
    "    \n",
    "#     URL = urls[item]\n",
    "#     ##return all data\n",
    "#     TOPIC = topics[item]\n",
    "#     OPtxt, OPwords, OPname = getOPtext(URL)\n",
    "#     comments, commentTXT, Names, deltalink, deltabot = getComments(URL)\n",
    "#     return(OPname, OPtxt, commentTXT, Names, URL, TOPIC, deltalink, deltabot)  \n",
    "\n",
    "# def get_next_page(url):\n",
    "#     url = souper(url).find_all(\"span\",attrs={'class':\"next-button\"})\n",
    "#     url = str(url).split('>')[1].split(\"\\\"\")[1]\n",
    "#     return url\n",
    "#deltapost = find_delta_txt(deltaNames, deltaComments, CommentText, commentName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPname, OPtxt, CommentText, commentName, URL, TOPIC, deltalink, deltabot= urlSearch(186)\n",
    "print(TOPIC)\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
